{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from time import time\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train1.csv')\n",
    "df2 = pd.read_csv('../testAll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(data.Dataset):\n",
    "    def __init__(self, users, items, ratings):\n",
    "        self.users = users \n",
    "        self.items =items\n",
    "        self.rating = ratings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.rating)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.users[idx]),torch.tensor(self.items[idx]), torch.tensor(self.rating[idx])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train = RatingDataset(df['userId']-1, df['movieId']-1, df['rating']*1.0)\n",
    "test = RatingDataset(df2['userId']-1, df2['movieId']-1, df2['rating']*1.0)\n",
    "\n",
    "bg = df['rating'].mean()\n",
    "n_users = df['userId'].max()\n",
    "n_items = df['movieId'].max()\n",
    "(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train, batch_size=100, shuffle=True)\n",
    "test_dataloader = data.DataLoader(test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=8):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=self.n_factors, out_features=1)\n",
    "#         self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        user_factors = self.user_factors(users)\n",
    "        item_factors = self.item_factors(items)\n",
    "        element_product = torch.mul(user_factors, item_factors)\n",
    "        ratings = self.affine_output(element_product)\n",
    "#         rating = self.logistic(logits)\n",
    "        return ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=8,layers =[16,64,32,16,8]):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=layers[-1], out_features=1)\n",
    "#         self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        user_factors = self.user_factors(users)\n",
    "        item_factors = self.item_factors(items)\n",
    "        vector = torch.cat([user_factors, item_factors], dim=-1)  # the concat latent vector\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            vector = self.fc_layers[idx](vector)\n",
    "            vector = nn.ReLU()(vector)\n",
    "            # vector = torch.nn.BatchNorm1d()(vector)\n",
    "            # vector = torch.nn.Dropout(p=0.5)(vector)\n",
    "        ratings = self.affine_output(vector)\n",
    "#         rating = self.logistic(logits)\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=8,layers =[16,64,32,16,8]):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_factors_mf = n_factors\n",
    "        self.n_factors_mlp = n_factors\n",
    "        \n",
    "        self.user_factor_mlp = nn.Embedding(n_users, n_factors)\n",
    "        self.item_factor_mlp = nn.Embedding(n_items, n_factors)\n",
    "        self.user_factor_mf = nn.Embedding(n_users, n_factors)\n",
    "        self.item_factor_mf = nn.Embedding(n_items, n_factors)\n",
    "#         self.init_weight()\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=layers[-1] + n_factors, out_features=1)\n",
    "#         self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        user_mlp = self.user_factor_mlp(users)\n",
    "        item_mlp = self.item_factor_mlp(items)\n",
    "        user_mf = self.user_factor_mf(users)\n",
    "        item_mf = self.item_factor_mf(items)\n",
    "\n",
    "        mlp_vector = torch.cat([user_mlp, item_mlp], dim=-1)  # the concat latent vector\n",
    "        mf_vector =torch.mul(user_mf, item_mf)\n",
    "\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            mlp_vector = self.fc_layers[idx](mlp_vector)\n",
    "            mlp_vector = nn.ReLU()(mlp_vector)\n",
    "\n",
    "        vector = torch.cat([mlp_vector, mf_vector], dim=-1)\n",
    "        ratings = self.affine_output(vector)\n",
    "#         rating = self.logistic(logits)\n",
    "        return ratings\n",
    "    \n",
    "    def init_weight(self):\n",
    "        nn.init.xavier_uniform_(self.user_factor_mlp.weight)\n",
    "        nn.init.xavier_uniform_(self.item_factor_mlp.weight)\n",
    "        nn.init.xavier_uniform_(self.user_factor_mf.weight)\n",
    "        nn.init.xavier_uniform_(self.item_factor_mf.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(n_users, n_items)\n",
    "loss_func = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([100, 1]) torch.Size([100])\n",
      "torch.Size([1, 1]) torch.Size([1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e42cbb9a0cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "epoches = 200\n",
    "L =[]\n",
    "mae=[]\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    l =0.0\n",
    "    for i,(users, items, ratings) in enumerate(train_dataloader):\n",
    "        users = Variable(torch.LongTensor(users))\n",
    "        items = Variable(torch.LongTensor(items))\n",
    "        ratings = Variable(torch.FloatTensor(ratings.float()))\n",
    "        \n",
    "        # Predict and calculate loss for user factor and bias\n",
    "        prediction = model(users, items)\n",
    "        if epoch==0: print(prediction.shape, ratings.shape)\n",
    "        loss = loss_func(prediction.squeeze(), ratings)    \n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        l += loss.item()\n",
    "    L.append(l)\n",
    "    \n",
    "    m = 0.0\n",
    "    total = 0\n",
    "    for j, (users, items, ratings) in enumerate(test_dataloader):\n",
    "        users = Variable(torch.LongTensor(users))\n",
    "        items = Variable(torch.LongTensor(items))\n",
    "        ratings = Variable(torch.FloatTensor(ratings.float()))\n",
    "\n",
    "        prediction = model(users, items)\n",
    "        m += l1_loss(prediction.round().squeeze(), ratings).item()\n",
    "        total += ratings.size(0)\n",
    "    m/=total\n",
    "#     if len(mae)!=0 and m > mae[-1]: break\n",
    "    mae.append(m) \n",
    "        \n",
    "print(round((time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure('Training Loss')\n",
    "x = range(len(L))\n",
    "plt.plot(x, L, color='g',linewidth=3)\n",
    "plt.title('Convergence curve')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(mae))\n",
    "plt.plot(x, mae, color='r',linewidth=3)\n",
    "plt.title('Convergence curve')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Test MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for j, (users, items, ratings) in enumerate(test_dataloader):\n",
    "    users = Variable(torch.LongTensor(users))\n",
    "    items = Variable(torch.LongTensor(items))\n",
    "    ratings = Variable(torch.FloatTensor(ratings.float()))\n",
    "\n",
    "    prediction = model(users, items)\n",
    "    pred.extend(prediction.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df2['rating']\n",
    "pred=torch.tensor(pred).round()\n",
    "target = torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss(pred.squeeze().float(), target)/target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
